{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW_N3cMkyGem"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2VxWXTS9qHv"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers --upgrade\n",
    "!pip install mosestokenizer\n",
    "!pip install sentencepiece\n",
    "!pip install ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evxq5mYA958q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, XLMRobertaForSequenceClassification, AdamW, BertConfig, BertTokenizer, XLMRobertaTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "LQngU_nG-ERC"
   },
   "outputs": [],
   "source": [
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6d3_pCj-GIJ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Construct object in BERT sentiment classifier class\n",
    "'''\n",
    "sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attention weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden states.\n",
    ")\n",
    "\n",
    "sentiment_model.cuda() # Puts model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "aymhFFrL-Wv5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load pretrained sentiment model parameters\n",
    "'''\n",
    "sentiment_model.load_state_dict(torch.load(\"/content/drive/My Drive/English_sentiment_model.pt\", map_location=torch.device('cpu')), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6kG2MTt4-z37"
   },
   "outputs": [],
   "source": [
    "sentiment_model.eval() # Put model in inference (as opposed to training) mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "f7gXH-HQ_JsW"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Load tokenizer for sentiment model\n",
    "'''\n",
    "sentiment_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySlU9vIR_5Nl"
   },
   "outputs": [],
   "source": [
    "# gets the text into the format we want\n",
    "def clean_tweet(tweet):\n",
    "  tweet = BeautifulSoup(tweet, \"lxml\").get_text() # turns xml-formatted text into regular text\n",
    "  tweet = re.sub(r\"@[A-Za-z0-9]+\", \" \", tweet) # gets rid of all user references in tweets (i.e. \"@username\")\n",
    "  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \", tweet) # gets rid of URLs\n",
    "  tweet = re.sub(r\"[^A-Za-z.!?áéíóúüñ¿ÁÉÍÓÚÜÑ']\", \" \", tweet) # gets rid of any non-standard characters in the tweets\n",
    "  tweet = re.sub(r\" +\", \" \", tweet) # replaces all excess whitespace with a single space\n",
    "\n",
    "  return tweet # gives us our cleaned tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgzAUDGQ_TDG"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(tweet):\n",
    "\n",
    "    '''\n",
    "    Predict the sentiment of an input text\n",
    "    '''\n",
    "    \n",
    "    tweet = clean_tweet(tweet)\n",
    "    tweet_input_id = []\n",
    "    tweet_attention_mask = []\n",
    "\n",
    "    tweet_dict = sentiment_tokenizer.encode_plus(\n",
    "                            tweet,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = 64,           # Pad & truncate all sentences.\n",
    "                            truncation=True,           # Explicitly enable truncation\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "    # Add the encoded sentence to the list.    \n",
    "    tweet_input_id.append(tweet_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    tweet_attention_mask.append(tweet_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    tweet_input_id = torch.cat(tweet_input_id, dim=0)\n",
    "    tweet_attention_mask = torch.cat(tweet_attention_mask, dim=0)\n",
    "\n",
    "    tweet_data = TensorDataset(tweet_input_id, tweet_attention_mask)\n",
    "    \n",
    "    tweet_dataloader = DataLoader(tweet_data)\n",
    "    \n",
    "    for data in tweet_dataloader:\n",
    "        tweet_input_id = data[0].to(device=torch.device('cuda'))\n",
    "        tweet_attention_mask = data[1].to(device=torch.device('cuda'))\n",
    "    \n",
    "    tweet_logits = sentiment_model(tweet_input_id, token_type_ids=None, attention_mask=tweet_attention_mask)\n",
    "    \n",
    "    tweet_logits = tweet_logits[0].detach().cpu().numpy()\n",
    "\n",
    "    tweet_logits = torch.Tensor(tweet_logits)\n",
    "\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    prob_dist = softmax(tweet_logits)\n",
    "\n",
    "    sentiment_pred = prob_dist.tolist()\n",
    "\n",
    "    sentiment_pred = sentiment_pred[0][1]\n",
    "\n",
    "    return sentiment_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmnE21a6ptU1"
   },
   "outputs": [],
   "source": [
    "#Another version of semantic distance here \n",
    "!pip install transformers\n",
    "!pip install sentence_transformers \n",
    "from transformers import pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZC2VIejrOYc"
   },
   "outputs": [],
   "source": [
    "#sentence level embeddings \n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "#example use \n",
    "# sentences = [\"Hello World\", \"Hallo Welt\"]\n",
    "# embeddings = model.encode(sentences)\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQpQSkHPddnG"
   },
   "outputs": [],
   "source": [
    "generations = pd.read_csv('https://raw.githubusercontent.com/gokulsrin/PossibilityGeneration/main/TimeData/LDmodified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO-bBym6X80d"
   },
   "outputs": [],
   "source": [
    "import math \n",
    "from scipy import spatial \n",
    "# def dist(r1, r2):\n",
    "#   r1 = np.array(r1)\n",
    "#   r2 = np.array(r2)\n",
    "#   return np.linalg.norm((r1 - r2), ord=2)\n",
    "def dist(r1, r2):\n",
    "  r1 = np.array(r1)\n",
    "  r2 = np.array(r2)\n",
    "  return spatial.distance.cosine(r1, r2)\n",
    "# def dist(r1, r2):\n",
    "#   r1 = np.array(r1)\n",
    "#   r2 = np.array(r2)\n",
    "#   return np.linalg.norm((r1 - r2), ord=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3d8PhjcxPpn"
   },
   "source": [
    "# **Total Semantic Exploration (adjusted) vs Average Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KL3sUaRjxVwJ"
   },
   "outputs": [],
   "source": [
    "#semantic exploration vs average sentiment\n",
    "exploration = {}\n",
    "individual_sentiment = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  exploration[id] = 0\n",
    "  individual_sentiment[id] = []\n",
    "  len_responses = 0\n",
    "  for vign, group2 in group.groupby(\"vignette_name\"):\n",
    "    embeddings = []\n",
    "    for response, group3 in group2.groupby(\"response\"):\n",
    "      if not pd.isna(response):\n",
    "        embeddings.append(model.encode(response))\n",
    "        individual_sentiment[id].append(predict_sentiment(response))\n",
    "    len_responses += len(embeddings)\n",
    "    for i in range(len(embeddings)):\n",
    "      for j in range(i+1, len(embeddings)):\n",
    "        exploration[id] += dist(embeddings[i], embeddings[j])\n",
    "  exploration[id] /= len_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNMOPOTYHFxI"
   },
   "outputs": [],
   "source": [
    "#find average sentiment \n",
    "for id in individual_sentiment:\n",
    "  individual_sentiment[id] = sum(individual_sentiment[id])/len(individual_sentiment[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmrjQHKtyZQ6"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for id in exploration:\n",
    "  # if .7 < individual_sentiment[id] < .9:\n",
    "    x.append(individual_sentiment[id])\n",
    "    y.append(exploration[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmYLRpPxyQXW"
   },
   "outputs": [],
   "source": [
    "#display adjusted exploration vs average sentiment \n",
    "import seaborn as sns \n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Average Sentiment', ylabel='Semantic Exploration', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvsnzTx7kUmt"
   },
   "outputs": [],
   "source": [
    "#try to combine the above two plots \n",
    "import plotnine\n",
    "from plotnine import ggplot, aes\n",
    "# package for plot scales\n",
    "from mizani.formatters import comma_format # (thousands seperator format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pTvEvcilnpF"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Average_Sentiment\", \"Semantic_Exploration\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Average_Sentiment', y='Semantic_Exploration'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5) + \n",
    " plotnine.xlab(\"Average Sentiment\") +\n",
    " plotnine.ylab(\"Semantic Exploration\") + \n",
    " plotnine.coords.coord_cartesian(ylim=(2,3)) +\n",
    " plotnine.theme_classic()\n",
    ").draw()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this reduces this axis to bwtween 0 and 1 \n",
    "#  plotnine.scale_y_continuous(limits=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUAxlsX3jirY"
   },
   "outputs": [],
   "source": [
    "def average_embedding(embeddings):\n",
    "  df = pd.DataFrame(embeddings)\n",
    "  df = df.mean(axis=0)\n",
    "  return df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZE6kgH21wcZ"
   },
   "source": [
    "# **Total Semantic Exploration vs Generation Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyueZ7Pl2BUW"
   },
   "outputs": [],
   "source": [
    "generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SptxZ4GtCSG"
   },
   "outputs": [],
   "source": [
    "# Real semantic exploration \n",
    "#exploration and answers tally average\n",
    "exploration = {}\n",
    "answers = {}\n",
    "#exp and nums tally the individual explorations\n",
    "exp = []\n",
    "nums = []\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  for pnum, group2 in group.groupby(\"generation_number\"):\n",
    "    if pnum not in exploration: \n",
    "      exploration[pnum] = []\n",
    "      # answers[pnum] = 0\n",
    "    embeddings = []\n",
    "    for response, group3 in group2.groupby(\"response\"):\n",
    "      response = group3['response'].to_list()[0]\n",
    "      if not pd.isna(response):\n",
    "        embeddings.append(model.encode(response).tolist())\n",
    "    # answers[pnum] += len(embeddings)\n",
    "    e = 0\n",
    "    for i in range(len(embeddings)):\n",
    "      for j in range(i+1, len(embeddings)):\n",
    "        # exploration[pnum] = dist_fn(embeddings[i], embeddings[j]) + exploration.get(pnum)\n",
    "        e += dist(embeddings[i], embeddings[j])\n",
    "    exploration[pnum].append(e/len(embeddings))\n",
    "    exp.append(e/len(embeddings))\n",
    "    nums.append(pnum)\n",
    "\n",
    "x_avg = []\n",
    "y_avg = []\n",
    "for num in exploration:\n",
    "  x_avg.append(num)\n",
    "  y_avg.append(sum(exploration[num])/len(exploration[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RexQKhx1ZeH"
   },
   "outputs": [],
   "source": [
    "#plotting for stats\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Average Semantic Exploration', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAHaU9KQxUWD"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[nums,exp])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Semantic_Exploration\"]\n",
    "\n",
    "d2 = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d2 = d2.T\n",
    "d2.columns = [\"Generation_Number\", \"Semantic_Exploration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FpsX-M-xUWD"
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for num, group in d.groupby(\"Generation_Number\"):\n",
    "  errors.append(group.std()[\"Semantic_Exploration\"]/(len(group))**.5)\n",
    "d2[\"yerr\"] = errors\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='Semantic_Exploration'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.3) +\n",
    " plotnine.geom_point(data=d2, color=\"red\", size=3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=.75, color=\"red\") + \n",
    " plotnine.geom_errorbar(d2,aes(x=\"Generation_Number\", ymin=\"Semantic_Exploration-yerr\",ymax=\"Semantic_Exploration+yerr\"), color=\"red\",width=.15) + \n",
    " plotnine.ylab(\"Semantic Exploration\") +\n",
    " plotnine.xlab(\"Generation Number\") +\n",
    "  plotnine.coords.coord_cartesian(ylim=(5,5.70)) +\n",
    " plotnine.theme_classic()\n",
    "  ).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qY_fLp4Mqtft"
   },
   "outputs": [],
   "source": [
    "def total_variation(e):\n",
    "  variation = 0\n",
    "  count = 0\n",
    "  for i in range(len(e)):\n",
    "    for j in range(i+1, len(e)):\n",
    "      variation += dist(e[i], e[j])\n",
    "      count += 1\n",
    "      if count%10000==0:\n",
    "        print(\"done\")\n",
    "  return variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa9-8o8U5epR"
   },
   "source": [
    "# **Semantic Dissimilarity vs Generation Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thAD4VkcI33v"
   },
   "outputs": [],
   "source": [
    "# Semantic space similarity vs possibiltiy number (pairwise sim between all avg. embedding vectors)\n",
    "vectordic = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  for pnum, group2 in group.groupby(\"generation_number\"):\n",
    "    if pnum not in vectordic:\n",
    "      vectordic[pnum] = []\n",
    "    embeddings = []\n",
    "    for generation in group2['response']:\n",
    "      if not pd.isna(generation):\n",
    "        embeddings.append(model.encode(generation))\n",
    "    embeddings = pd.DataFrame(embeddings)\n",
    "    embeddings = embeddings.mean(axis=0)\n",
    "    embeddings = embeddings.values.tolist()\n",
    "    vectordic.get(pnum).append(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kq1xkkjSpj1"
   },
   "outputs": [],
   "source": [
    "#semantic space dissimilarity vs generation nums\n",
    "similarity = []\n",
    "nums = []\n",
    "avg_dic = {}\n",
    "for num in vectordic:\n",
    "  avg_dic[num] = []\n",
    "  for i in range(len(vectordic.get(num))):\n",
    "    for j in range(i+1, len(vectordic.get(num))):\n",
    "      nums.append(num)\n",
    "      s = dist(vectordic.get(num)[i], vectordic.get(num)[j])\n",
    "      similarity.append(s)\n",
    "      avg_dic[num].append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sL_8YznRmCJ6"
   },
   "outputs": [],
   "source": [
    "# remove invalid data - why would the distance between two distinct localizing vectors be 0? \n",
    "x = nums\n",
    "y = similarity\n",
    "i = 0 \n",
    "avg_dic = {}\n",
    "while i < len(x):\n",
    "  if y[i] == 0:\n",
    "    y.pop(i)\n",
    "    x.pop(i)\n",
    "    i -= 1\n",
    "  else:\n",
    "    if x[i] not in avg_dic:\n",
    "      avg_dic[x[i]] = []\n",
    "    avg_dic[x[i]].append(y[i])\n",
    "  i += 1\n",
    "x_avg = []\n",
    "y_avg = []\n",
    "for num in avg_dic:\n",
    "  avg_dic[num] = sum(avg_dic[num])/len(avg_dic[num])\n",
    "  x_avg.append(num)\n",
    "  y_avg.append(avg_dic[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVgd8oRO7EUj"
   },
   "outputs": [],
   "source": [
    "#plotting to find stats \n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Semantic Dissimilarity', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEmdAG_X2CD6"
   },
   "outputs": [],
   "source": [
    "#plotting to find stats \n",
    "\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Semantic Dissimilarity', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3T5OJGpngw4"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Semantic_Dissimilarity\"]\n",
    "\n",
    "d2 = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d2 = d2.T\n",
    "d2.columns = [\"Generation_Number\", \"Semantic_Dissimilarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQk7Hz7FoTaD"
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for num, group in d.groupby(\"Generation_Number\"):\n",
    "  errors.append(group.std()[\"Semantic_Dissimilarity\"]/(len(group))**.5)\n",
    "d2[\"yerr\"] = errors\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='Semantic_Dissimilarity'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.1) +\n",
    " plotnine.geom_point(data=d2, color=\"red\", size=3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=.75, color=\"red\") + \n",
    " plotnine.geom_errorbar(d2,aes(x=\"Generation_Number\", ymin=\"Semantic_Dissimilarity-yerr\",ymax=\"Semantic_Dissimilarity+yerr\"), color=\"red\",width=.15) + \n",
    " plotnine.ylab(\"Semantic Dissimilarity\") +\n",
    " plotnine.xlab(\"Generation Number\") +\n",
    "  plotnine.coords.coord_cartesian(ylim=(.4,.5)) +\n",
    " plotnine.theme_classic()\n",
    "  ).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ehBV7wBVfZh"
   },
   "outputs": [],
   "source": [
    "generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN-e647q7i06"
   },
   "source": [
    "# **Subjective Goodness vs Generation Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNAxfdWdUUte"
   },
   "outputs": [],
   "source": [
    "#average goodness rating per possibility \n",
    "scores = [[] for i in range(8)]\n",
    "nums = [i for i in range(8)]\n",
    "\n",
    "#all of the ratings \n",
    "s = []\n",
    "n = []\n",
    "\n",
    "for pnum, group1 in generations.groupby(\"generation_number\"):\n",
    "  print(len(group1))\n",
    "  for score in group1['reflection_score']:\n",
    "    scores[pnum-1].append(score)\n",
    "    s.append(score)\n",
    "    n.append(pnum)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "  scores[i] = sum(scores[i])/len(scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyLfJUOp1wwG"
   },
   "outputs": [],
   "source": [
    "#plotting for stats\n",
    "x_avg = np.array(nums) \n",
    "y_avg = np.array(scores)\n",
    "\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Subjective Rationality', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOhlmCjaZCl_"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[n,s])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Generation_Goodness\"]\n",
    "\n",
    "d2 = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d2 = d2.T\n",
    "d2.columns = [\"Generation_Number\", \"Generation_Goodness\"]\n",
    "\n",
    "errors = []\n",
    "for num, group in d.groupby(\"Generation_Number\"):\n",
    "  errors.append(group.std()[\"Generation_Goodness\"]/(len(group[\"Generation_Goodness\"])**.5))\n",
    "d2[\"yerr\"] = errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO9iQjV8lyqW"
   },
   "outputs": [],
   "source": [
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='Generation_Goodness'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.3) +\n",
    " plotnine.geom_point(data=d2, color=\"red\", size=3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=.75, color=\"red\") + \n",
    " plotnine.geom_errorbar(d2,aes(x=\"Generation_Number\", ymin=\"Generation_Goodness-yerr\",ymax=\"Generation_Goodness+yerr\"), color=\"red\",width=.15) + \n",
    " plotnine.ylab(\"Subjective Rationality\") +\n",
    " plotnine.xlab(\"Generation Number\") + \n",
    " plotnine.theme_classic()  +\n",
    " plotnine.coords.coord_cartesian(ylim=(35,80)) \n",
    " ).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0xiIKhy9i0D"
   },
   "source": [
    "# **Generation Sentiment vs Generation Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bh1Mztty99Dv"
   },
   "outputs": [],
   "source": [
    "#generation sentiment vs generation number\n",
    "\n",
    "sentiment = []\n",
    "nums = []\n",
    "avg_sentiment = {}\n",
    "for id, participant in generations.groupby('id'):\n",
    "  for pos_num, group in participant.groupby('generation_number'):\n",
    "    if pos_num not in avg_sentiment:\n",
    "      avg_sentiment[pos_num] = []\n",
    "    for generation in group['response']:\n",
    "      if not pd.isna(generation):\n",
    "        s = predict_sentiment(generation)\n",
    "        sentiment.append(s)\n",
    "        nums.append(pos_num)\n",
    "        avg_sentiment[pos_num].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DJpInrep26b"
   },
   "outputs": [],
   "source": [
    "x = nums\n",
    "y = sentiment\n",
    "\n",
    "x_avg = []\n",
    "y_avg = []\n",
    "for num in avg_sentiment:\n",
    "  x_avg.append(num)\n",
    "  y_avg.append(sum(avg_sentiment[num])/len(avg_sentiment[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFrcj9Hu16gz"
   },
   "outputs": [],
   "source": [
    "#plotting for stats \n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Average Sentiment', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj_TSOxTq5I5"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Generation_Sentiment\"]\n",
    "\n",
    "d2 = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d2 = d2.T\n",
    "d2.columns = [\"Generation_Number\", \"Generation_Sentiment\"]\n",
    "\n",
    "errors = []\n",
    "for num, group in d.groupby(\"Generation_Number\"):\n",
    "  errors.append(group.std()[\"Generation_Sentiment\"]/(len(group[\"Generation_Sentiment\"])**.5))\n",
    "d2[\"yerr\"] = errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyZ72HOLrZax"
   },
   "outputs": [],
   "source": [
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='Generation_Sentiment'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.3) +\n",
    " plotnine.geom_point(data=d2, color=\"red\", size=3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=.75, color=\"red\") + \n",
    " plotnine.geom_errorbar(d2,aes(x=\"Generation_Number\", ymin=\"Generation_Sentiment-yerr\",ymax=\"Generation_Sentiment+yerr\"), color=\"red\",width=.15) + \n",
    " plotnine.ylab(\"Generation Sentiment\") +\n",
    " plotnine.xlab(\"Generation Number\") + \n",
    " plotnine.theme_classic() +\n",
    " plotnine.coords.coord_cartesian(ylim=(.55,.65)) \n",
    ").draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hqufw5AW_ZEf"
   },
   "source": [
    "# **Generation Concreteness vs Generation Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPy3hQWe0IoN"
   },
   "outputs": [],
   "source": [
    "concreteness = pd.read_csv(\"https://raw.githubusercontent.com/gokulsrin/PossibilityGeneration/main/Misc/Concreteness_ratings_Brysbaert_et_al_BRM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZD10yWny8-Y"
   },
   "outputs": [],
   "source": [
    "#create concreteness dict\n",
    "concreteness_dict = {}\n",
    "for word, group in concreteness.groupby(\"Word\"):\n",
    "  rating = group[\"Conc.M\"].values[0]\n",
    "  concreteness_dict[word] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7gKIN0yy9A9"
   },
   "outputs": [],
   "source": [
    "#figure out if later generations are more or less concrete \n",
    "import string \n",
    "\n",
    "conc = []\n",
    "nums = []\n",
    "cdic = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  for vign, group2 in group.groupby(\"vignette_name\"):\n",
    "    for num, group3 in group2.groupby(\"generation_number\"):\n",
    "      for response, group4 in group3.groupby(\"response\"):\n",
    "        if not pd.isna(response):\n",
    "          response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "          score = []\n",
    "          l = len(response.split(\" \"))\n",
    "          for word in response.split(\" \"):\n",
    "            if word in concreteness_dict:\n",
    "              score.append(concreteness_dict[word])\n",
    "          if len(score) > 0:\n",
    "            score = sum(score)/len(score)\n",
    "            # score = (sum(score)/len(score))/l\n",
    "            conc.append(score)\n",
    "            nums.append(num)\n",
    "            if num not in cdic:\n",
    "              cdic[num] = []\n",
    "            cdic[num].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQIiYMo6uEzK"
   },
   "outputs": [],
   "source": [
    "#find averages in concreteness differences\n",
    "x_avg = []\n",
    "y_avg = [] \n",
    "for key in cdic:\n",
    "  cdic[key] = sum(cdic[key])/len(cdic[key])\n",
    "  x_avg.append(key)\n",
    "  y_avg.append(cdic[key])\n",
    "\n",
    "print(cdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24ZQ3qEYLWKX"
   },
   "outputs": [],
   "source": [
    "#just for stats\n",
    "\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Generation Concreteness', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lIiYv1R8zSB"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[nums,conc])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Generation_Concreteness\"]\n",
    "\n",
    "d2 = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d2 = d2.T\n",
    "d2.columns = [\"Generation_Number\", \"Generation_Concreteness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLAZCF6R9YHU"
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for num, group in d.groupby(\"Generation_Number\"):\n",
    "  errors.append(group.std()[\"Generation_Concreteness\"]/(len(group))**.5)\n",
    "d2[\"yerr\"] = errors\n",
    "\n",
    "scatter = ggplot(data=d2, mapping=aes(x='Generation_Number', y='Generation_Concreteness', ymin=2.7))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.2) +\n",
    " plotnine.geom_point(data=d2, color=\"red\", size=3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=.70, color=\"red\", se=False) + \n",
    " plotnine.geom_errorbar(d2,aes(x=\"Generation_Number\", ymin=\"Generation_Concreteness-yerr\",ymax=\"Generation_Concreteness+yerr\"), color=\"red\",width=.15) + \n",
    " plotnine.ylab(\"Generation Concreteness\") +\n",
    " plotnine.xlab(\"Generation Number\") + \n",
    "  plotnine.coords.coord_cartesian(ylim=(2.6,2.9))\n",
    "  ).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COVYeWYZ1Idn"
   },
   "source": [
    "# **Concreteness vs Semantic Relatedness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYDTwxNF1FMN"
   },
   "outputs": [],
   "source": [
    "#bin the generations based on concreteness \n",
    "gens = {}\n",
    "for response, group in generations.groupby(\"response\"):\n",
    "    response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "    score = []\n",
    "    l = len(response.split(\" \"))\n",
    "    for word in response.split(\" \"):\n",
    "      if word in concreteness_dict:\n",
    "        score.append(concreteness_dict[word])\n",
    "    if len(score) > 0:\n",
    "      score = sum(score)/len(score)\n",
    "      gens[response] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HG0bSDpf31M7"
   },
   "outputs": [],
   "source": [
    "#bin all of the responses : num bins = 10 \n",
    "gens = dict(sorted(gens.items(), key=lambda item: item[1]))\n",
    "len(gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBMOZqlN2gmw"
   },
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "bins = [[] for j in range(nbins)]\n",
    "i = 0 \n",
    "for item in gens:\n",
    "  if i//int(len(gens)/nbins) < nbins:\n",
    "    bins[i//int(len(gens)/nbins)].append((item, gens[item]))\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXVcbmxaAW-V"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jIgubFC5I2T"
   },
   "outputs": [],
   "source": [
    "similarity = {}\n",
    "for b in tqdm(range(len(bins))):\n",
    "  if b not in similarity: \n",
    "    similarity[b] = []\n",
    "  bin = bins[b]\n",
    "  embeddings = {}\n",
    "  for response in bin:\n",
    "    response = response[0]\n",
    "    embeddings[response] = model.encode(response)\n",
    "  for i in range(len(bin)):\n",
    "    for j in range(i+1, len(bin)):\n",
    "      similarity[b].append(dist(embeddings[bin[i][0]], embeddings[bin[j][0]]))\n",
    "  print(b)\n",
    "similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gantzaJL6QCY"
   },
   "outputs": [],
   "source": [
    "buckets = {}\n",
    "for key in similarity:\n",
    "  buckets[key] = sum(similarity[key])/len(similarity[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRobCVHC9DBW"
   },
   "outputs": [],
   "source": [
    "x_avg = []\n",
    "y_avg = []\n",
    "\n",
    "for key in buckets:\n",
    "  x_avg.append(key)\n",
    "  y_avg.append(buckets[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5-zSERGCkX2"
   },
   "outputs": [],
   "source": [
    "# to be clear, higher buckets have higher concreteness. \n",
    "\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Concreteness Bucket', ylabel='Semantic Dissimilarity', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pM0nMOsJJpTs"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d = d.T\n",
    "d.columns = [\"Concreteness_Bucket\", \"Semantic_Dissimilarity\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Concreteness_Bucket', y='Semantic_Dissimilarity'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5, color=\"red\") + \n",
    " plotnine.xlab(\"Concreteness Bucket\") +\n",
    " plotnine.ylab(\"Semantic Dissimilarity\") + \n",
    " plotnine.theme_classic()\n",
    ").draw()\n",
    "\n",
    "#this reduces this axis to bwtween 0 and 1 \n",
    "#  plotnine.scale_y_continuous(limits=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP1XuSWEpM_k"
   },
   "outputs": [],
   "source": [
    "#replication of this experiment with a third model\n",
    "#################################### \n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoViAuFbpkk6"
   },
   "outputs": [],
   "source": [
    "#bin the generations based on concreteness \n",
    "gens = {}\n",
    "for response, group in generations.groupby(\"response\"):\n",
    "    response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "    score = []\n",
    "    l = len(response.split(\" \"))\n",
    "    for word in response.split(\" \"):\n",
    "      if word in concreteness_dict:\n",
    "        score.append(concreteness_dict[word])\n",
    "    if len(score) > 0:\n",
    "      score = sum(score)/len(score)\n",
    "      gens[response] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPa0cYvIpkk6"
   },
   "outputs": [],
   "source": [
    "#bin all of the responses : num bins = 10 \n",
    "gens = dict(sorted(gens.items(), key=lambda item: item[1]))\n",
    "len(gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReWPQrI6pkk7"
   },
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "bins = [[] for j in range(nbins)]\n",
    "i = 0 \n",
    "for item in gens:\n",
    "  if i//int(len(gens)/nbins) < nbins:\n",
    "    bins[i//int(len(gens)/nbins)].append((item, gens[item]))\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LV29FHyXpkk7"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQ8lte-ppkk7"
   },
   "outputs": [],
   "source": [
    "similarity = {}\n",
    "for b in tqdm(range(len(bins))):\n",
    "  if b not in similarity: \n",
    "    similarity[b] = []\n",
    "  bin = bins[b]\n",
    "  embeddings = {}\n",
    "  for response in bin:\n",
    "    response = response[0]\n",
    "    embeddings[response] = model.encode(response)\n",
    "  for i in range(len(bin)):\n",
    "    for j in range(i+1, len(bin)):\n",
    "      similarity[b].append(dist(embeddings[bin[i][0]], embeddings[bin[j][0]]))\n",
    "  print(b)\n",
    "similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3b8IbH1pkk7"
   },
   "outputs": [],
   "source": [
    "buckets = {}\n",
    "for key in similarity:\n",
    "  buckets[key] = sum(similarity[key])/len(similarity[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EL5mwcGppkk7"
   },
   "outputs": [],
   "source": [
    "x_avg = []\n",
    "y_avg = []\n",
    "\n",
    "for key in buckets:\n",
    "  x_avg.append(key)\n",
    "  y_avg.append(buckets[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMRvohqNpkk7"
   },
   "outputs": [],
   "source": [
    "# to be clear, higher buckets have higher concreteness. \n",
    "\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Concreteness Bucket', ylabel='Semantic Dissimilarity', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EqjXNduH2Qq"
   },
   "source": [
    "# **Semantic Exploration vs Average Concreteness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "466Jiv-QNvp7"
   },
   "outputs": [],
   "source": [
    "# semantic exploration \n",
    "exploration = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  exploration[id] = 0\n",
    "  len_responses = 0\n",
    "  for vign, group2 in group.groupby(\"vignette_name\"):\n",
    "    embeddings = []\n",
    "    for response, group3 in group2.groupby(\"response\"):\n",
    "      if not pd.isna(response):\n",
    "        embeddings.append(model.encode(response))\n",
    "    len_responses += len(embeddings)\n",
    "    for i in range(len(embeddings)):\n",
    "      for j in range(i+1, len(embeddings)):\n",
    "        exploration[id] += dist(embeddings[i], embeddings[j])\n",
    "  exploration[id] /= len_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwHypvhcG-O1"
   },
   "outputs": [],
   "source": [
    "#determine avg concreteness \n",
    "id_concreteness = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  for response, group2 in group.groupby(\"response\"):\n",
    "    response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "    score = []\n",
    "    l = len(response.split(\" \"))\n",
    "    for word in response.split(\" \"):\n",
    "      if word in concreteness_dict:\n",
    "        score.append(concreteness_dict[word])\n",
    "    if len(score) > 0:\n",
    "      if id not in id_concreteness:\n",
    "        id_concreteness[id] = []\n",
    "      score = sum(score)/len(score)\n",
    "      id_concreteness[id].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6ZjHtm1Ii7g"
   },
   "outputs": [],
   "source": [
    "for id in id_concreteness:\n",
    "  id_concreteness[id] = sum(id_concreteness[id])/len(id_concreteness[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPiqi1JKIyTZ"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for id in id_concreteness:\n",
    "  if id in exploration:\n",
    "    x.append(id_concreteness[id])\n",
    "    y.append(exploration[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPBnAlcNIyTb"
   },
   "outputs": [],
   "source": [
    "#display adjusted exploration vs average sentiment \n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Average Concreteness', ylabel='Semantic Exploration', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3tFulzuJFgm"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Average_Concreteness\", \"Semantic_Exploration\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Average_Concreteness', y='Semantic_Exploration'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5, color=\"red\") + \n",
    " plotnine.xlab(\"Average Concreteness\") +\n",
    " plotnine.ylab(\"Semantic Exploration\") + \n",
    " plotnine.theme_classic() + \n",
    " plotnine.coords.coord_cartesian(ylim=(2,3.5))\n",
    ").draw()\n",
    "\n",
    "#this reduces this axis to bwtween 0 and 1 \n",
    "#  plotnine.scale_y_continuous(limits=(0, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5iuRtjSDcLE"
   },
   "source": [
    "# **Generation Concreteness vs Subjective Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdV4uWlmC3ri"
   },
   "outputs": [],
   "source": [
    "concreteness = []\n",
    "subjective = []\n",
    "for response, group in generations.groupby(\"response\"):\n",
    "  response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "  score = []\n",
    "  l = len(response.split(\" \"))\n",
    "  for word in response.split(\" \"):\n",
    "    if word in concreteness_dict:\n",
    "      score.append(concreteness_dict[word])\n",
    "  if len(score) > 0 :\n",
    "    score = sum(score)/len(score)\n",
    "    concreteness.append(score)\n",
    "    subjective.append(list(group[\"reflection_score\"])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlHazaZ9GLMp"
   },
   "outputs": [],
   "source": [
    "x = concreteness\n",
    "y = subjective\n",
    "\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Concreteness', ylabel='Subjective Score', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBryxHlUDUA6"
   },
   "source": [
    "# **Generation Concreteness vs Generation Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Gdd288IDutk"
   },
   "outputs": [],
   "source": [
    "concreteness = []\n",
    "sentiment = []\n",
    "for response, group in generations.groupby(\"response\"):\n",
    "  response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "  score = []\n",
    "  l = len(response.split(\" \"))\n",
    "  for word in response.split(\" \"):\n",
    "    if word in concreteness_dict:\n",
    "      score.append(concreteness_dict[word])\n",
    "  if len(score) > 0:\n",
    "    score = sum(score)/len(score)\n",
    "    concreteness.append(score)\n",
    "    sentiment.append(predict_sentiment(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9zLuVRBGEnT"
   },
   "outputs": [],
   "source": [
    "x = concreteness\n",
    "y = sentiment\n",
    "\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Concreteness', ylabel='Sentiment', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzcBzA7C_Sq6"
   },
   "source": [
    "# **Timed Analysis**\n",
    "Results to develop here: \n",
    "\n",
    "\n",
    "1.   Total sematic exploration (adjusted) vs time\n",
    "2.   Successive Semantic Distance vs time\n",
    "3.  Time vs Distance from center of mass \n",
    "4.  Total time vs Generation Number\n",
    "5. Generation Time v Concreteness \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmyv1NgNAQK2"
   },
   "source": [
    "# **Total Semantic Exploration (adjusted) vs Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgPXQHhwAZr-"
   },
   "outputs": [],
   "source": [
    "generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOp6lMPXzHk1"
   },
   "outputs": [],
   "source": [
    "# total (adjusted) exploration vs total generation time \n",
    "exploration = {}\n",
    "times = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  exploration[id] = 0\n",
    "  times[id] = 0\n",
    "  len_responses = 0\n",
    "  for vign, group2 in group.groupby(\"vignette_name\"):\n",
    "    embeddings = []\n",
    "    for response, group3 in group2.groupby(\"response\"):\n",
    "      if not pd.isna(response):\n",
    "        embeddings.append(model.encode(response))\n",
    "        times[id] += list(group3[\"generation_time\"])[0]\n",
    "    len_responses += len(embeddings)\n",
    "    for i in range(len(embeddings)):\n",
    "      for j in range(i+1, len(embeddings)):\n",
    "        exploration[id] += dist(embeddings[i], embeddings[j])\n",
    "  exploration[id] /= len_responses\n",
    "  times[id] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaFTS-SS61hj"
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for id in exploration:\n",
    "  x.append(times[id])\n",
    "  y.append(exploration[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U79A2wKV7Clv"
   },
   "outputs": [],
   "source": [
    "#just for stats\n",
    "\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Total Generation Time', ylabel='Total Semantic Exploration', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7K3MfycU9tAk"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Semantic_Exploration\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='Semantic_Exploration'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.5) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5, color=\"red\") + \n",
    " plotnine.xlab(\"Generation Number\") +\n",
    " plotnine.ylab(\"Semantic Exploration\") + \n",
    " plotnine.coords.coord_cartesian(ylim=(2,3)) + \n",
    " plotnine.theme_classic()\n",
    ").draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUnD2m79CmRC"
   },
   "source": [
    "# **Successive Semantic Distance vs Generation Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlnGAoU7CrUf"
   },
   "outputs": [],
   "source": [
    "distance = []\n",
    "time = []\n",
    "\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  for vign, group2 in group.groupby(\"vignette_name\"):\n",
    "    embeddings = []\n",
    "    times = []\n",
    "    for response, group3 in group2.groupby(\"response\"):\n",
    "      if not pd.isna(response):\n",
    "        embeddings.append(model.encode(response))\n",
    "        times.append(list(group3[\"generation_time\"])[0])\n",
    "    for i in range(len(embeddings)-1):\n",
    "      j = i+1\n",
    "      distance.append(dist(embeddings[i], embeddings[j]))\n",
    "      time.append(times[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNCNhOyQHBHS"
   },
   "outputs": [],
   "source": [
    "#just for stats\n",
    "x = np.array(time)\n",
    "y = distance\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Generation Time', ylabel='Successive Semantic Distance', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtjfRZTQHXfM"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Successive_Semantic_Distance\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='Successive_Semantic_Distance'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.5) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5, color=\"red\") + \n",
    " plotnine.xlab(\"Generation Number\") +\n",
    " plotnine.ylab(\"Successive Semantic Distance\") + \n",
    " plotnine.theme_classic()\n",
    ").draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fClpt-HVEE4Q"
   },
   "source": [
    "# **Distance from Center of Mass vs Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NI4FXUDhFWOb"
   },
   "outputs": [],
   "source": [
    "def average_embedding(embeddings):\n",
    "  df = pd.DataFrame(embeddings)\n",
    "  df = df.mean(axis=0)\n",
    "  return df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcS7TgXm83mu"
   },
   "outputs": [],
   "source": [
    "DCOM = []\n",
    "time = []\n",
    "for id,group in generations.groupby(\"id\"):\n",
    "  for vign, group2 in group.groupby(\"vignette_name\"):\n",
    "    embeddings = []\n",
    "    responses = []\n",
    "    times = []\n",
    "    for num, group3 in group2.groupby(\"generation_number\"):\n",
    "      responses.append(list(group3[\"response\"])[0])\n",
    "      times.append(list(group3[\"generation_time\"])[0])\n",
    "    for row in zip(responses, times):\n",
    "      response = row[0]\n",
    "      gtime = row[1]\n",
    "      if not pd.isna(response):\n",
    "        if len(embeddings) > 0:\n",
    "          current = model.encode(response)\n",
    "          COM = average_embedding(embeddings)\n",
    "          DCOM.append(dist(current, COM))\n",
    "          time.append(gtime)\n",
    "        embeddings.append(model.encode(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ_lrglVH3AG"
   },
   "outputs": [],
   "source": [
    "x = np.array(time)\n",
    "y = DCOM\n",
    "#just for stats\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Generation Time', ylabel='Distance from Center of Mass', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEVnYghpIgzY"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"DCOM\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Number', y='DCOM'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.5) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5, color=\"red\") + \n",
    " plotnine.xlab(\"Generation Number\") +\n",
    " plotnine.ylab(\"Distance from Center of Mass\") + \n",
    " plotnine.theme_classic()\n",
    ").draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boPnnXIBG0_L"
   },
   "source": [
    "# **Total Time vs Generation Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lp7xkJlaIK_A"
   },
   "outputs": [],
   "source": [
    "#Total time vs possibility number\n",
    "time = []\n",
    "nums = []\n",
    "times = {}\n",
    "for id, group in generations.groupby(\"id\"):\n",
    "  for pnum, group1 in group.groupby(\"generation_number\"):\n",
    "    if pnum not in times:\n",
    "      times[pnum] = []\n",
    "    for response, group2 in group1.groupby(\"response\"):\n",
    "      t = list(group2[\"generation_time\"])[0]\n",
    "      times[pnum].append(t)\n",
    "      time.append(t)\n",
    "      nums.append(pnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMaSzhOEKbP0"
   },
   "outputs": [],
   "source": [
    "x_avg = [i for i in range(8)]\n",
    "y_avg = []\n",
    "for num in times:\n",
    "  y_avg.append(sum(times[num])/len(times[num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqB2QbQCKeFm"
   },
   "outputs": [],
   "source": [
    "\n",
    "#just for stats\n",
    "g = sns.jointplot(x=x_avg, y=y_avg, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x_avg, y_avg)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x_avg, y_avg)\n",
    "g.set_axis_labels(xlabel='Generation Number', ylabel='Total Time', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlqqQDixK4dJ"
   },
   "outputs": [],
   "source": [
    "nums = np.array(nums)\n",
    "time = np.array(time)\n",
    "d = pd.DataFrame(data=[nums,time])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Number\", \"Generation_Time\"]\n",
    "y_avg = np.array(y_avg)\n",
    "d2 = pd.DataFrame(data=[x_avg,y_avg])\n",
    "d2 = d2.T\n",
    "d2.columns = [\"Generation_Number\", \"Generation_Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M8z3ACkK4dK"
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for num, group in d.groupby(\"Generation_Number\"):\n",
    "  errors.append(group.std()[\"Generation_Time\"]/(len(group))**.5)\n",
    "d2[\"yerr\"] = errors\n",
    "\n",
    "scatter = ggplot(data=d2, mapping=aes(x='Generation_Number', y='Generation_Time'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.4) +\n",
    " plotnine.geom_point(data=d2, color=\"red\", size=3) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=.70, color=\"red\", se=False) + \n",
    " plotnine.geom_errorbar(d2,aes(x=\"Generation_Number\", ymin=\"Generation_Time-yerr\",ymax=\"Generation_Time+yerr\"), color=\"red\",width=.15) + \n",
    " plotnine.ylab(\"Generation Time\") +\n",
    " plotnine.xlab(\"Generation Number\") + \n",
    "  plotnine.coords.coord_cartesian(ylim=(5,25)) + \n",
    " plotnine.theme_classic()\n",
    "  ).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mac1Zpu4IAlG"
   },
   "source": [
    "# **Generation Concreteness vs Generation Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjkxvlxiMEj6"
   },
   "outputs": [],
   "source": [
    "gc = []\n",
    "time = []\n",
    "\n",
    "for response, group in generations.groupby(\"response\"):\n",
    "  response = response.translate(str.maketrans('', '', string.punctuation))\n",
    "  score = []\n",
    "  l = len(response.split(\" \"))\n",
    "  for word in response.split(\" \"):\n",
    "    if word in concreteness_dict:\n",
    "      score.append(concreteness_dict[word])\n",
    "  if len(score) > 0:\n",
    "    score = sum(score)/len(score)\n",
    "    gc.append(score)\n",
    "    time.append(list(group[\"generation_time\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QP2lpy6WMtmG"
   },
   "outputs": [],
   "source": [
    "x = np.array(time)/1000\n",
    "y= gc\n",
    "#just for stats\n",
    "g = sns.jointplot(x=x, y=y, kind='reg', color='royalblue')\n",
    "# ax.annotate(stats.pearsonr)\n",
    "r, p = stats.pearsonr(x, y)\n",
    "g.ax_joint.annotate(f'$\\\\rho = {r:.3f}, p = {p:.3f}$',\n",
    "                    xy=(0.1, 0.9), xycoords='axes fraction',\n",
    "                    ha='left', va='center',\n",
    "                    bbox={'boxstyle': 'round', 'fc': 'powderblue', 'ec': 'navy'})\n",
    "g.ax_joint.scatter(x, y)\n",
    "g.set_axis_labels(xlabel='Generation Time (s)', ylabel='Generation Concreteness', size=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEvCpkjeNFDB"
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data=[x,y])\n",
    "d = d.T\n",
    "d.columns = [\"Generation_Time\", \"Generation_Concreteness\"]\n",
    "# d[(np.abs(stats.zscore(d)) < 3).all(axis=1)]\n",
    "\n",
    "scatter = ggplot(data=d, mapping=aes(x='Generation_Time', y='Generation_Concreteness'))\n",
    "# add layers\n",
    "(scatter + \n",
    " plotnine.geom_jitter(data=d, color=\"black\", alpha=0.5) +\n",
    " plotnine.geom_smooth(method=\"lm\",size=1.5, color=\"red\") + \n",
    " plotnine.xlab(\"Generation Time\") +\n",
    " plotnine.ylab(\"Generation Concreteness\") + \n",
    " plotnine.theme_classic()\n",
    ").draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do5zqIPGHc-t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QZE6kgH21wcZ",
    "Wa9-8o8U5epR",
    "WN-e647q7i06",
    "R0xiIKhy9i0D",
    "Hqufw5AW_ZEf",
    "COVYeWYZ1Idn",
    "5EqjXNduH2Qq",
    "g5iuRtjSDcLE",
    "fBryxHlUDUA6",
    "XzcBzA7C_Sq6",
    "dmyv1NgNAQK2",
    "pUnD2m79CmRC",
    "fClpt-HVEE4Q",
    "boPnnXIBG0_L",
    "Mac1Zpu4IAlG"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
